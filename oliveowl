#!/bin/bash

# oliveowl - Terminal AI Chat Assistant

# --- Configuration ---
CONFIG_DIR="$HOME/.config/oliveowl"
ENV_FILE="$CONFIG_DIR/.env"
HISTORY_DIR="$CONFIG_DIR/history"
CONFIG_FILE="$CONFIG_DIR/config"

# --- Dependency Checks ---
check_dependency() {
  if ! command -v "$1" &>/dev/null; then
    echo "Error: Required command '$1' not found. Please install it." >&2
    exit 1
  fi
}

check_clipboard_tool() {
  # Try wl-copy first: check if command exists AND if it runs without error (e.g., connects to Wayland)
  if command -v wl-copy &>/dev/null && printf '' | wl-copy &>/dev/null; then
    CLIPBOARD_TOOL="wl-copy"
    echo "Using clipboard tool: wl-copy" # Optional: for debugging
  # If wl-copy fails or isn't present, try xclip
  elif command -v xclip &>/dev/null; then
    CLIPBOARD_TOOL="xclip -selection clipboard"
    echo "Using clipboard tool: xclip" # Optional: for debugging
  else
    # Error: Neither working wl-copy nor xclip found
    echo "Error: No functional clipboard tool found (need working 'wl-copy' for Wayland or 'xclip' for X11)." >&2
    exit 1
  fi
  # The debug echo is now inside the if/elif blocks
}

check_dependency "curl"
check_dependency "jq"
check_dependency "fzf"
check_dependency "bat"
check_dependency "gum" # Added gum dependency check
check_clipboard_tool   # Sets $CLIPBOARD_TOOL

# --- Initial Setup ---
setup_config() {
  mkdir -p "$CONFIG_DIR"
  mkdir -p "$HISTORY_DIR"

  if [ ! -f "$ENV_FILE" ]; then
    echo "Creating initial config file: $ENV_FILE"
    echo "# Add your API keys here" >"$ENV_FILE"
    echo "GEMINI_API_KEY=" >>"$ENV_FILE"
    echo "OPENROUTER_API_KEY=" >>"$ENV_FILE"
    echo "OPENAI_API_KEY=" >>"$ENV_FILE"
    echo "CEREBRAS_API_KEY=" >>"$ENV_FILE"
    echo "# Ollama base URL (e.g., http://localhost:11434)" >>"$ENV_FILE"
    echo "OLLAMA_BASE_URL=" >>"$ENV_FILE"
    chmod 600 "$ENV_FILE" # Secure the file
    echo "Please edit $ENV_FILE and add your API keys and/or Ollama URL."
    # Optionally exit here or prompt user
  fi

  # Load environment variables
  set -a # Automatically export all variables
  # Check if ENV_FILE exists before sourcing
  if [ -f "$ENV_FILE" ]; then
    source "$ENV_FILE"
  else
    echo "Warning: Environment file $ENV_FILE not found." >&2
  fi
  set +a

  # Check if keys are set (basic check)
  if [ -z "$GEMINI_API_KEY" ] && [ -z "$OPENROUTER_API_KEY" ] && [ -z "$OPENAI_API_KEY" ] && [ -z "$CEREBRAS_API_KEY" ] && [ -z "$OLLAMA_BASE_URL" ]; then
    echo "Warning: No API keys (Gemini, OpenRouter, OpenAI, Cerebras) or OLLAMA_BASE_URL found in $ENV_FILE. Please configure at least one." >&2
    # Decide if we should exit or continue
  fi

  # Load or create config file
  if [ ! -f "$CONFIG_FILE" ]; then
    echo "Creating default settings file: $CONFIG_FILE"
    echo "API_PROVIDER=" >"$CONFIG_FILE" # Will be 'gemini' or 'openrouter'
    echo "MODEL=" >>"$CONFIG_FILE"
    echo "EDITOR=\"vi\"" >>"$CONFIG_FILE" # Add default editor
  fi

  # Load config settings
  # Check if CONFIG_FILE exists before sourcing
  if [ -f "$CONFIG_FILE" ]; then
    source "$CONFIG_FILE"
  else
    echo "Warning: Config file $CONFIG_FILE not found. Using defaults." >&2
  fi

  # Set default editor if not found in config
  EDITOR="${EDITOR:-vi}"

  # NOTE: Configuration completeness check moved to main()
  # Ensure EDITOR command exists - Moved to after setup_config call before main()
}

# --- Configuration Function ---
fetch_openrouter_models() {
  local models_json
  echo "Fetching models from OpenRouter..." >&2
  models_json=$(curl -s https://openrouter.ai/api/v1/models)
  if [ $? -ne 0 ] || [ -z "$models_json" ]; then
    echo "Error: Failed to fetch models from OpenRouter." >&2
    return 1
  fi
  # Extract model IDs, filter out duplicates, sort
  echo "$models_json" | jq -r '.data[].id' | sort -u
}

fetch_openai_models() {
  if [ -z "$OPENAI_API_KEY" ]; then
    echo "Error: OPENAI_API_KEY not set in $ENV_FILE. Cannot fetch models." >&2
    return 1
  fi

  local models_json
  echo "Fetching models from OpenAI..." >&2
  models_json=$(curl -s -H "Authorization: Bearer $OPENAI_API_KEY" https://api.openai.com/v1/models)

  if [ $? -ne 0 ] || [ -z "$models_json" ]; then
    echo "Error: Failed to fetch models from OpenAI." >&2
    return 1
  fi

  # Check for API errors
  local openai_error=$(echo "$models_json" | jq -r '.error.message // empty')
  if [ -n "$openai_error" ]; then
    echo "Warning: OpenAI API Error when fetching models: $openai_error" >&2
    return 1
  fi

  # Check if data array exists (like OpenAI)
  if ! echo "$models_json" | jq -e '.data | type == "array"' >/dev/null 2>&1; then
    echo "Warning: Invalid JSON or missing 'data' array in OpenAI models response." >&2
    # echo "OpenAI response: $models_json" >&2 # For debugging
    return 1
  fi

  # Extract model IDs, filter out duplicates, sort
  local extracted_models
  extracted_models=$(echo "$models_json" | jq -r '.data[].id // empty' | sort -u | grep .)

  if [ -z "$extracted_models" ]; then
    echo "Warning: No models found in OpenAI response or failed to parse names." >&2
    return 1
  fi

  echo "$extracted_models"
  return 0 # Success
}

fetch_cerebras_models() {
  if [ -z "$CEREBRAS_API_KEY" ]; then
    echo "Error: CEREBRAS_API_KEY not set in $ENV_FILE. Cannot fetch models." >&2
    return 1
  fi

  local models_json
  echo "Fetching models from Cerebras..." >&2
  models_json=$(curl -s -H "Authorization: Bearer $CEREBRAS_API_KEY" https://api.cerebras.ai/v1/models)

  if [ $? -ne 0 ] || [ -z "$models_json" ]; then
    echo "Error: Failed to fetch models from Cerebras." >&2
    return 1
  fi

  # Check for API errors
  local cerebras_error=$(echo "$models_json" | jq -r '.error.message // empty')
  if [ -n "$cerebras_error" ]; then
    echo "Warning: Cerebras API Error when fetching models: $cerebras_error" >&2
    return 1
  fi

  # Check if data array exists (like OpenAI)
  if ! echo "$models_json" | jq -e '.data | type == "array"' >/dev/null 2>&1; then
    echo "Warning: Invalid JSON or missing 'data' array in Cerebras models response." >&2
    # echo "Cerebras response: $models_json" >&2 # For debugging
    return 1
  fi

  # Extract model IDs, filter out duplicates, sort
  local extracted_models
  extracted_models=$(echo "$models_json" | jq -r '.data[].id // empty' | sort -u | grep .)

  if [ -z "$extracted_models" ]; then
    echo "Warning: No models found in Cerebras response or failed to parse names." >&2
    return 1
  fi

  echo "$extracted_models"
  return 0 # Success
}

# Function to fetch models from a local Ollama instance
fetch_ollama_models() {
  local ollama_url_base="${OLLAMA_BASE_URL:-http://localhost:11434}"
  # Remove trailing slash if present
  ollama_url_base=$(echo "$ollama_url_base" | sed 's:/*$::')
  local models_api_url="${ollama_url_base}/api/tags"
  local models_json

  echo "Fetching models from Ollama at $ollama_url_base..." >&2
  # Timeout curl after 5 seconds for local requests to avoid long hangs
  models_json=$(curl --connect-timeout 5 -s "$models_api_url")

  if [ $? -ne 0 ]; then
    echo "Warning: curl command failed for Ollama. Is Ollama running and accessible at $ollama_url_base?" >&2
    return 1
  fi

  if [ -z "$models_json" ]; then
    echo "Warning: Received empty response from Ollama models API." >&2
    return 1
  fi

  # Check for Ollama API errors (e.g., if the endpoint exists but returns an error object)
  local ollama_error=$(echo "$models_json" | jq -r '.error // empty')
  if [ -n "$ollama_error" ]; then
    echo "Warning: Ollama API Error when fetching models: $ollama_error" >&2
    return 1
  fi

  # Check if the 'models' array exists and is an array
  if ! echo "$models_json" | jq -e '.models | type == "array"' >/dev/null 2>&1; then
    echo "Warning: Invalid JSON or missing 'models' array in Ollama response." >&2
    # echo "Ollama response: $models_json" >&2 # For debugging
    return 1
  fi

  # Extract model names, filter out duplicates, sort
  local extracted_models
  extracted_models=$(echo "$models_json" | jq -r '.models[].name // empty' | sort -u | grep .) # grep . to remove empty lines if any

  if [ -z "$extracted_models" ]; then
    echo "Warning: No models found in Ollama response or failed to parse names." >&2
    return 1 # Indicate no models found or parse error
  fi

  echo "$extracted_models"
  return 0 # Success
}

configure_settings() {
  echo "--- OliveOwl Configuration ---"

  # 1. Select API Provider
  local providers="Gemini\nOpenRouter\nOpenAI\nOllama\nCerebras" # Added OpenAI
  API_PROVIDER=$(echo -e "$providers" | fzf --prompt="Select API Provider: " --height=7 --layout=reverse) # Use fixed height, adjusted for OpenAI

  if [ -z "$API_PROVIDER" ]; then
    echo "Configuration cancelled."
    exit 1
  fi

  # 2. Select Model
  local model_list=""
  local fetched_models=""
  local fzf_input=""
  local manual_entry_option="-- Manual Model Entry --"

  case "$API_PROVIDER" in
  "Gemini")
    # Check for Gemini Key first
    if [ -z "$GEMINI_API_KEY" ]; then
      echo "Warning: GEMINI_API_KEY not set in $ENV_FILE. Cannot fetch models." >&2
      # Proceed with only manual entry option
    else
      echo "Fetching Gemini models..."
      local gemini_url="https://generativelanguage.googleapis.com/v1beta/models?key=$GEMINI_API_KEY"
      local gemini_response=$(curl -s "$gemini_url")
      if [ $? -ne 0 ]; then
        echo "Warning: curl command failed for Gemini. Using manual entry only." >&2
      else
        local gemini_error=$(echo "$gemini_response" | jq -r '.error.message // empty')
        if [ -n "$gemini_error" ]; then
          echo "Warning: Gemini API Error: $gemini_error. Using manual entry only." >&2
        elif echo "$gemini_response" | jq -e '.models' >/dev/null 2>&1; then
          fetched_models=$(echo "$gemini_response" | jq -r '.models[].name')
          if [ -z "$fetched_models" ]; then
            echo "Warning: No models found in Gemini response. Using manual entry only." >&2
          fi
        else
          echo "Warning: Invalid JSON or missing 'models' in Gemini response. Using manual entry only." >&2
        fi
      fi
    fi
    ;;
  "OpenRouter")
    # OpenRouter key not strictly needed for model listing, but good practice to have it set for actual use later
    if [ -z "$OPENROUTER_API_KEY" ]; then
      echo "Warning: OPENROUTER_API_KEY not set in $ENV_FILE. You will need it to use OpenRouter models." >&2
      # Continue fetching anyway, as the endpoint is public
    fi
    # The fetch_openrouter_models function handles its own "Fetching..." message and errors.
    fetched_models=$(fetch_openrouter_models)
    if [ $? -ne 0 ] || [ -z "$fetched_models" ]; then
      # fetch_openrouter_models already prints detailed errors to stderr.
      # This message just confirms fallback to manual entry.
      echo "Warning: Using manual entry for OpenRouter models due to fetch error or no models found." >&2
      fetched_models="" # Ensure it's empty so the manual entry path is taken later
    fi
    ;;
  "OpenAI")
    # The fetch_openai_models function handles its own "Fetching..." message and errors.
    fetched_models=$(fetch_openai_models)
    if [ $? -ne 0 ] || [ -z "$fetched_models" ]; then
      # fetch_openai_models already prints detailed errors to stderr.
      echo "Warning: Using manual entry for OpenAI models due to fetch error or no models found." >&2
      fetched_models="" # Ensure it's empty so the manual entry path is taken later
    else
      echo "Successfully fetched OpenAI models." >&2
    fi
    ;;
  "Cerebras")
    # The fetch_cerebras_models function handles its own "Fetching..." message and errors.
    fetched_models=$(fetch_cerebras_models)
    if [ $? -ne 0 ] || [ -z "$fetched_models" ]; then
      # fetch_cerebras_models already prints detailed errors to stderr.
      echo "Warning: Using manual entry for Cerebras models due to fetch error or no models found." >&2
      fetched_models="" # Ensure it's empty so the manual entry path is taken later
    else
      echo "Successfully fetched Cerebras models." >&2
    fi
    ;;
  "Ollama")
    # OLLAMA_BASE_URL from .env will be used by call_api and fetch_ollama_models.
    # Check if OLLAMA_BASE_URL is set, if not, fetching will use default.
    if [ -z "$OLLAMA_BASE_URL" ]; then
      echo "Info: OLLAMA_BASE_URL not set in $ENV_FILE. Will attempt to fetch models from default http://localhost:11434." >&2
    fi
    fetched_ollama_models=$(fetch_ollama_models)
    if [ $? -eq 0 ] && [ -n "$fetched_ollama_models" ]; then
      fetched_models="$fetched_ollama_models"
      echo "Successfully fetched Ollama models." >&2
    else
      echo "Warning: Could not fetch Ollama models. Using manual entry only." >&2
      fetched_models="" # Ensure it's empty on failure
    fi
    ;;
  *)
    echo "Invalid provider selected."
    exit 1
    ;;
  esac

  # Prepare input for fzf: Manual option first, then fetched models
  fzf_input="$manual_entry_option"
  if [ -n "$fetched_models" ]; then
    # Sort models alphabetically for better usability
    fetched_models=$(echo "$fetched_models" | sort)
    fzf_input="$fzf_input\n$fetched_models"
  fi

  # Use fzf for selection
  MODEL=$(echo -e "$fzf_input" | fzf --prompt="Select Model for $API_PROVIDER: " --height=15 --layout=reverse)

  # Handle fzf cancellation
  if [ -z "$MODEL" ]; then
    echo "Configuration cancelled."
    exit 1
  fi

  # Check if manual entry was selected
  if [[ "$MODEL" == "$manual_entry_option" ]]; then
    echo "Manual entry selected."
    MODEL=$(gum input --placeholder "Enter exact model name/ID for $API_PROVIDER...")
    # Handle cancellation of gum input
    if [ $? -ne 0 ] || [ -z "$MODEL" ]; then
      echo "Manual entry cancelled or empty. Configuration cancelled."
      exit 1
    fi
  fi
  # MODEL variable now holds either the selected fetched model or the manually entered one

  # 3. Configure Editor
  local current_editor=${EDITOR:-vi} # Get current or default from sourced config or default
  local new_editor
  new_editor=$(gum input --header "Configure Editor" --placeholder "Enter preferred editor command (current: $current_editor)..." --value "$current_editor")
  # Update EDITOR only if gum input succeeded and value is not empty
  if [ $? -eq 0 ] && [ -n "$new_editor" ]; then
    EDITOR="$new_editor"
  fi

  # 4. Save Configuration
  echo "Saving configuration..."
  echo "API_PROVIDER=\"$API_PROVIDER\"" >"$CONFIG_FILE"
  echo "MODEL=\"$MODEL\"" >>"$CONFIG_FILE"
  echo "EDITOR=\"$EDITOR\"" >>"$CONFIG_FILE" # Save editor setting

  echo "Configuration saved to $CONFIG_FILE:"
  echo "  Provider: $API_PROVIDER"
  echo "  Model: $MODEL"
  echo "  Editor: $EDITOR"
  echo "Setup complete. You can now run '$0'." # Use $0 for the current script name
}

# --- System Prompt ---
# Instructs the AI on formatting and behavior
SYSTEM_PROMPT="""You are a helpful AI assistant. Answer user questions clearly and concisely.

For regular questions, respond in natural language without using code blocks.

ONLY use Markdown code blocks when providing code, commands, scripts, or any content that users might need to copy and paste. This includes:
- Shell commands (bash, zsh, fish)
- Programming code (Python, JavaScript, etc.)
- Configuration files
- Docker commands
- Git commands
- Ollama commands
- Game commands (Minecraft, etc.)
- HTML/CSS/SQL or other markup/query languages

When using code blocks, format them properly so they can be copied and used directly:
```bash
echo "example command"
```

For all other responses, use plain text without code blocks.
"""

# --- History Management ---
CHAT_HISTORY=() # In-memory array of JSON objects for the current session
CURRENT_HISTORY_FILE=""

# Function to create the API-specific JSON object string for a message
# Usage: create_api_message_json "role" "content"
# Returns a compact JSON string suitable for the configured API provider
create_api_message_json() {
  local role="$1"
  local content="$2"
  # Content is passed directly, assuming it doesn't need pre-escaping for jq --arg
  # json_content=$(echo "$content" | jq -Rsa .) # REMOVED

  if [[ "$API_PROVIDER" == "Gemini" ]]; then
    # Gemini uses "user" and "model" roles, and a "parts" array
    local gemini_role="$role"
    # Map OpenRouter's 'assistant' role if needed (though we primarily use 'model' for Gemini AI responses)
    if [[ "$role" == "assistant" ]]; then
      gemini_role="model"
    fi
    # Simple text part for now - Pass content directly to --arg text_content
    # jq needs the value for "text" to be a valid JSON string. Let jq handle the encoding.
    jq -n --arg role "$gemini_role" --arg text_content "$content" \
      '{role: $role, parts: [{"text": $text_content}]}' | jq -c .
  else # OpenRouter uses "user" and "assistant"
    local openrouter_role="$role"
    # Map Gemini's 'model' role if needed (though we primarily use 'assistant' for OpenRouter AI responses)
    if [[ "$role" == "model" ]]; then
      openrouter_role="assistant"
    fi
    # Pass content directly to --arg content
    jq -n --arg role "$openrouter_role" --arg content "$content" \
      '{role: $role, content: $content}' | jq -c .
  fi
}

# Function to load history from a file into the CHAT_HISTORY array
# Usage: load_history "path/to/history.json"
load_history() {
  local file_path="$1"
  if [ ! -f "$file_path" ]; then
    echo "History file not found: $file_path" >&2
    return 1
  fi
  # Read the JSON array from the file. Each element is an object string.
  # Store each object string as an element in the CHAT_HISTORY bash array.
  mapfile -t CHAT_HISTORY < <(jq -c '.[]' "$file_path")
  if [ $? -ne 0 ]; then
    echo "Error: Failed to parse history file: $file_path" >&2
    CHAT_HISTORY=() # Clear history on parse error
    return 1
  fi
  CURRENT_HISTORY_FILE="$file_path"
  echo "Loaded history from: $CURRENT_HISTORY_FILE"
}

# Function to display the current CHAT_HISTORY
display_history() {
  echo "--- Chat History ---"
  # Iterate through the CHAT_HISTORY array (each element is a JSON string object)
  for history_item_json in "${CHAT_HISTORY[@]}"; do
    # Parse the outer object to get message_json and model_used
    local message_json model_used role content display_model_name
    message_json=$(echo "$history_item_json" | jq -r '.message_json // empty')
    model_used=$(echo "$history_item_json" | jq -r '.model_used // empty') # Will be empty for user messages

    if [ -z "$message_json" ]; then
      echo "Warning: Skipping invalid history item." >&2
      continue
    fi

    # Parse the inner message_json to get role and content
    role=$(echo "$message_json" | jq -r '.role')
    # Extract the raw content string
    content=$(echo "$message_json" | jq -r 'if .parts then .parts[0].text else .content end')

    if [[ "$role" == "user" ]]; then
      # Display directly, assuming jq -r decoded correctly
      echo -e "\n\e[1m\e[34mYou:\e[0m" # Print prompt (Bold Blue)
      echo "$content"
    elif [[ "$role" == "model" || "$role" == "assistant" ]]; then
      # Use the specific model_used if available, otherwise fall back to the current $MODEL
      display_model_name="${model_used:-$MODEL}"
      echo -e "\n\e[1m\e[35mAI ($display_model_name):\e[0m"                   # Bold Purple for AI, showing specific model, with explicit reset
      echo -e "\e[1m\e[35m=============================================\e[0m" # Bold Purple for AI, showing specific model, with explicit reset
      # Pipe the extracted content directly to bat, assuming jq -r decoded correctly
      echo "$content" | bat --language md --paging=never --style=plain --color=always
    # Handle potential 'system' role if it ever gets stored/displayed (currently shouldn't)
    # elif [[ "$role" == "system" ]]; then
    #   echo -e "\n\e[35mSystem:\e[0m $content" # Magenta for system
    fi
  done
  echo "--------------------"
}

# Function to select and load a history file using fzf
# Returns 0 on success, 1 on failure/cancel
select_and_load_history() {
  # List ALL .json files, sorted by time (most recent first)
  # We need full paths for fzf to pass to bat for previewing.
  local history_files_with_paths
  # Find .json files in HISTORY_DIR, print full path, sort by modification time (newest first)
  # Using find is more robust than ls for parsing filenames, especially with spaces or special chars.
  # However, for simple .json files generated by our script, ls -t is likely fine.
  # Let's stick closer to your current `ls -t` approach for now, but ensure paths are handled.

  # Get full paths, then pipe to fzf.
  # The `ls -t "$HISTORY_DIR"/*.json` already gives paths relative to CWD if HISTORY_DIR is relative,
  # or full paths if HISTORY_DIR is absolute. For `bat` to work reliably in the preview,
  # `fzf` needs to receive paths that `bat` can directly use.
  # If $HISTORY_DIR is always absolute (e.g., starting with $HOME), then `ls -t` output is fine.
  # If $HISTORY_DIR could be relative, like "./history", we need to ensure fzf gets resolvable paths.
  # Assuming $HISTORY_DIR is robustly defined (e.g. $CONFIG_DIR/history which is $HOME/.config/oliveowl/history)

  # Check if any history files exist
  if ! compgen -G "$HISTORY_DIR/*.json" > /dev/null; then
    echo "No history files found in $HISTORY_DIR."
    return 1 # Indicate failure
  fi

  # Use fzf with preview. fzf will pass the selected line (full path) to bat.
  # The {} in the bat command will be replaced by fzf with the selected line.
  local chosen_file_path # This will now store the full path directly from fzf

  # We pass the output of `ls -t ...` directly to fzf.
  # fzf will display the full paths, which might be long.
  # The client's example used `find ... | fzf --read0 --preview ...`,
  # which is good for handling all sorts of filenames.
  # For simplicity and consistency with current `ls -t`, we will pipe `ls -t` output.
  # If filenames contain newlines (not expected for our .json files), this `ls` approach can break.

  # Get list of files sorted by time
  # Store in an array to handle potential spaces if we weren't using find -print0
  mapfile -t history_files_sorted < <(ls -t "$HISTORY_DIR"/*.json 2>/dev/null)

  if [ ${#history_files_sorted[@]} -eq 0 ]; then
    echo "No history files found." # Should be caught by compgen, but double-check
    return 1
  fi

  # Pipe the array elements (full paths) to fzf, one per line
  chosen_file_path=$(printf "%s\n" "${history_files_sorted[@]}" | \
    fzf --prompt="Select chat history to load (Preview with bat): " \
        --height=100% --layout=reverse \
        --preview 'bat --style=numbers --color=always --language=json {}' \
        --preview-window=right:60%:wrap \
        --bind ctrl-/:toggle-preview)
        # The client's example bind `ctrl-/:toggle-preview` is good, let's keep it.

  # Check if fzf returned a selection (chosen_file_path is not empty)
  # and also check fzf's exit status. 0 for selection, 1 for Esc/no selection, 130 for Ctrl+C.
  if [ $? -eq 0 ] && [ -n "$chosen_file_path" ]; then
    # chosen_file_path already contains the full path to the selected file.
    # No need to reconstruct it.
    clear # Clear the terminal screen
    load_history "$chosen_file_path" # load_history already prints messages
    display_history
    return 0 # Indicate success
  else
    echo "History loading cancelled or no selection made."
    return 1 # Indicate failure/cancel
  fi
}

# Function to save the current CHAT_HISTORY array to CURRENT_HISTORY_FILE
save_history() {
  if [ -z "$CURRENT_HISTORY_FILE" ]; then
    echo "Error: No history file set for saving." >&2
    return 1
  fi
  # Convert the bash array of JSON strings into a single JSON array string and save
  if printf "%s\n" "${CHAT_HISTORY[@]}" | jq -s '.' >"$CURRENT_HISTORY_FILE"; then
    # Optional: echo "History saved successfully to: $CURRENT_HISTORY_FILE" >&2
    : # No-op, command succeeded
  else
    echo "Error: Failed to save history to $CURRENT_HISTORY_FILE" >&2
    # Decide if we should return an error code? For now, just print error.
    return 1 # Indicate save failure
  fi
}

# Function to format and view history in editor
view_history() {
  if [ ${#CHAT_HISTORY[@]} -eq 0 ]; then
    echo "Chat history is empty. Nothing to view."
    return
  fi

  local temp_history_file
  temp_history_file=$(mktemp --suffix=.md) # Create temp markdown file
  # Ensure temp file is deleted on exit/interrupt
  trap 'rm -f "$temp_history_file" 2>/dev/null' EXIT INT TERM HUP

  echo "# Chat History ($(date))" >"$temp_history_file"
  echo "" >>"$temp_history_file"

  # Iterate through history and format as Markdown
  for history_item_json in "${CHAT_HISTORY[@]}"; do
    local message_json model_used role content display_model_name
    message_json=$(echo "$history_item_json" | jq -r '.message_json // empty')
    model_used=$(echo "$history_item_json" | jq -r '.model_used // empty')

    if [ -z "$message_json" ]; then continue; fi # Skip invalid items

    role=$(echo "$message_json" | jq -r '.role')
    content=$(echo "$message_json" | jq -r 'if .parts then .parts[0].text else .content end')

    if [[ "$role" == "user" ]]; then
      echo "### You:" >>"$temp_history_file"
      echo "" >>"$temp_history_file"
      echo "$content" >>"$temp_history_file"
    elif [[ "$role" == "model" || "$role" == "assistant" ]]; then
      display_model_name="${model_used:-$MODEL}"
      echo "### AI ($display_model_name):" >>"$temp_history_file"
      echo "" >>"$temp_history_file"
      echo "$content" >>"$temp_history_file" # Raw content, editor handles wrapping
    fi
    echo "" >>"$temp_history_file"
    echo "---" >>"$temp_history_file" # Separator
    echo "" >>"$temp_history_file"
  done

  # Open the temp file in the configured editor
  "$EDITOR" "$temp_history_file"

  # Remove trap and delete file explicitly after editor closes
  trap - EXIT INT TERM HUP
  rm -f "$temp_history_file" 2>/dev/null
  echo "Resuming chat..." # Indicate return to chat
}

# Function to create the actual new session file
# Takes an optional session name as argument
create_new_session_file() {
  local session_name="$1" # Optional name passed from start_new_session
  local filename timestamp sanitized_name

  CHAT_HISTORY=() # Clear in-memory history for the new session

  timestamp=$(date +"%Y%m%d_%H%M%S")

  if [ -z "$session_name" ]; then
    filename="chat_${timestamp}.json"
    echo "Starting new timestamped chat session..."
  else
    # Sanitize the name: replace spaces with underscores, remove non-alphanumeric/-/_ characters
    sanitized_name=$(echo "$session_name" | sed -e 's/ /_/g' -e 's/[^a-zA-Z0-9_-]//g')
    if [ -z "$sanitized_name" ]; then # Handle case where sanitization removes everything
      filename="chat_${timestamp}.json"
      echo "Invalid name provided, using timestamp..."
    else
      # Append timestamp to user-provided name to avoid collisions easily
      filename="${sanitized_name}_${timestamp}.json"
      echo "Starting new named chat session..."
    fi
  fi

  CURRENT_HISTORY_FILE="$HISTORY_DIR/$filename"
  echo "[]" >"$CURRENT_HISTORY_FILE" # Create empty JSON array file
  echo "Session file: $CURRENT_HISTORY_FILE"
}

# Function to handle the initial session prompt (new, load history, or exit)
# Returns 0 if a session was started (new or loaded), 1 if history loading failed/cancelled
start_new_session() {
  local user_choice

  # Prompt for session name or command
  # Prompt for session name or command using gum input
  user_choice=$(gum input --placeholder "Enter name for new chat session (or /history, /config, /exit)")

  # Check if gum input was cancelled (e.g., Ctrl+C or Esc)
  if [ $? -ne 0 ]; then
    echo "Input cancelled. Exiting."
    exit 1
  fi

  case "$user_choice" in
  "/exit")
    gum style --foreground "#FF0000" --bold "Exiting OliveOwl."
    exit 0
    ;;
  "/history")
    select_and_load_history # This function handles messages and returns status
    return $?               # Return status (0 for success, 1 for fail/cancel)
    ;;
  "/config")
    echo "Switching to config..."
    configure_settings # Re-run config
    # Re-source config in case it changed
    if [ -f "$CONFIG_FILE" ]; then
      source "$CONFIG_FILE"
    fi
    echo "Config updated. Provider: $API_PROVIDER, Model: $MODEL"
    # After config, prompt again for session action
    start_new_session # Recursive call
    return $?         # Return status from the recursive call
    ;;
  *)
    # Treat anything else (name or blank) as a request for a new session
    create_new_session_file "$user_choice"
    return 0 # Indicate success (new session created)
    ;;
  esac
}

# --- API Call Implementation ---
# Takes user input, sends history + input to API, returns AI response text
call_api() {
  local user_input="$1"
  local api_url api_key payload response response_text error_message

  # 1. Prepare payload: Convert history messages to the format required by the CURRENT API provider
  local converted_messages=()
  for history_item_json in "${CHAT_HISTORY[@]}"; do
    # Extract the raw message_json string from the wrapper object string
    local original_msg_json=$(echo "$history_item_json" | jq -r '.message_json // empty')
    if [ -z "$original_msg_json" ]; then
      echo "Warning: Skipping empty message_json in history item." >&2
      continue
    fi

    # Parse the original message to get role and content, regardless of format
    local original_role original_content
    original_role=$(echo "$original_msg_json" | jq -r '.role')
    # Try extracting from Gemini format first, then OpenRouter format
    original_content=$(echo "$original_msg_json" | jq -r 'if .parts then .parts[0].text else .content end // empty')

    if [ -z "$original_role" ] || [ -z "$original_content" ]; then
      echo "Warning: Skipping history item with missing role or content: $original_msg_json" >&2
      continue
    fi

    # Convert the extracted role/content to the format needed by the CURRENT provider
    local converted_msg_json=$(create_api_message_json "$original_role" "$original_content")
    if [ -n "$converted_msg_json" ]; then
      converted_messages+=("$converted_msg_json")
    else
      echo "Warning: Failed to convert history message: $original_msg_json" >&2
    fi
  done
  # Combine the *converted* message JSON strings into a single JSON array string for the API
  local history_json_array=$(printf "%s\n" "${converted_messages[@]}" | jq -s '.')

  # 2. Set API specifics based on provider
  if [[ "$API_PROVIDER" == "Gemini" ]]; then
    api_key="$GEMINI_API_KEY"
    # Note: Gemini API URL structure might vary slightly based on region or specific model version. Adjust if needed.
    # Using v1beta for generative models as it's common.
    # The MODEL variable fetched from the API already contains the "models/" prefix.
    api_url="https://generativelanguage.googleapis.com/v1beta/${MODEL}:generateContent?key=${api_key}"

    # Gemini payload structure: { "contents": [history array], "systemInstruction": { "parts": [{"text": "..."}] } }
    # Construct the payload JSON using jq for proper escaping
    payload=$(jq -n --argjson history "$history_json_array" --arg system_prompt "$SYSTEM_PROMPT" \
      '{contents: $history, systemInstruction: {parts: [{"text": $system_prompt}]}}')

    # 3. Make the curl request for Gemini
    response=$(curl -s -X POST "$api_url" \
      -H "Content-Type: application/json" \
      -d "$payload")

    # 4. Parse Gemini response and handle errors
    if [ $? -ne 0 ]; then
      echo "Error: curl command failed for Gemini." >&2
      return 1
    fi

    # Check for API errors in the response JSON
    error_message=$(echo "$response" | jq -r '.error.message // empty')
    if [ -n "$error_message" ]; then
      echo "Error: Gemini API Error: $error_message" >&2
      # You might want to see the full error: echo "$response" >&2
      return 1
    fi

    # Extract the text content. Gemini nests it under candidates -> content -> parts -> text
    # It might return multiple candidates, usually the first is sufficient.
    # It might also return multiple parts, concatenate them.
    response_text=$(echo "$response" | jq -r '.candidates[0].content.parts[]?.text // empty' | paste -sd '\n')

    if [ -z "$response_text" ]; then
      # Handle cases like safety blocks or empty responses
      local finish_reason=$(echo "$response" | jq -r '.candidates[0].finishReason // "UNKNOWN"')
      if [[ "$finish_reason" == "SAFETY" ]]; then
        echo "Warning: Gemini response blocked due to safety settings." >&2
        response_text="[Response blocked by safety settings]"
      elif [[ "$finish_reason" == "RECITATION" ]]; then
        echo "Warning: Gemini response blocked due to recitation policy." >&2
        response_text="[Response blocked by recitation policy]"
      else
        echo "Error: Could not extract text from Gemini response. Finish Reason: $finish_reason" >&2
        echo "Full Gemini Response: $response" >&2 # Temporarily uncommented for debugging
        return 1
      fi
    fi

  elif [[ "$API_PROVIDER" == "OpenRouter" ]]; then
    api_key="$OPENROUTER_API_KEY"
    api_url="https://openrouter.ai/api/v1/chat/completions"

    # OpenRouter payload structure: { "model": "...", "messages": [history array including system prompt] }
    # Create the system message JSON separately
    local system_message_json=$(create_api_message_json "system" "$SYSTEM_PROMPT")
    # Prepend the system message JSON string to the extracted history array string
    # Note: history_json_array already contains the user/assistant messages
    local messages_json_array_with_system=$(echo "$history_json_array" | jq --argjson sys_msg "$system_message_json" '[$sys_msg] + .')

    payload=$(jq -n --arg model "$MODEL" --argjson messages "$messages_json_array_with_system" \
      '{model: $model, messages: $messages}')
    # Add other parameters like temperature, max_tokens if desired:
    # '{model: $model, messages: $messages, temperature: 0.7, max_tokens: 1024}'

    # 3. Make the curl request for OpenRouter
    response=$(curl -s -X POST "$api_url" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $api_key" \
      -H "HTTP-Referer: http://localhost" \
      -H "X-Title: OliveOwl CLI" \
      -d "$payload")

    # 4. Parse OpenRouter response and handle errors
    if [ $? -ne 0 ]; then
      echo "Error: curl command failed for OpenRouter." >&2
      return 1
    fi

    # Check for API errors
    error_message=$(echo "$response" | jq -r '.error.message // empty')
    if [ -n "$error_message" ]; then
      echo "Error: OpenRouter API Error: $error_message" >&2
      # echo "Full OpenRouter Response: $response" >&2 # for debugging
      return 1
    fi

    # Extract the text content. OpenRouter nests it under choices -> message -> content
    response_text=$(echo "$response" | jq -r '.choices[0].message.content // empty')

    if [ -z "$response_text" ]; then
      echo "Error: Could not extract text from OpenRouter response." >&2
      # echo "Full OpenRouter Response: $response" >&2 # for debugging
      return 1
    fi

  elif [[ "$API_PROVIDER" == "OpenAI" ]]; then
    api_key="$OPENAI_API_KEY"
    api_url="https://api.openai.com/v1/chat/completions"

    # OpenAI payload is like OpenRouter: { "model": "...", "messages": [...] }
    local system_message_json=$(create_api_message_json "system" "$SYSTEM_PROMPT")
    local messages_json_array_with_system=$(echo "$history_json_array" | jq --argjson sys_msg "$system_message_json" '[$sys_msg] + .')

    payload=$(jq -n --arg model "$MODEL" --argjson messages "$messages_json_array_with_system" \
      '{model: $model, messages: $messages}')

    # Make the curl request for OpenAI
    response=$(curl -s -X POST "$api_url" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $api_key" \
      -d "$payload")

    # Parse OpenAI response and handle errors
    if [ $? -ne 0 ]; then
      echo "Error: curl command failed for OpenAI." >&2
      return 1
    fi

    # Check for API errors
    error_message=$(echo "$response" | jq -r '.error.message // empty')
    if [ -n "$error_message" ]; then
      echo "Error: OpenAI API Error: $error_message" >&2
      # echo "Full OpenAI Response: $response" >&2 # for debugging
      return 1
    fi

    # Extract the text content. OpenAI nests it under choices -> message -> content
    response_text=$(echo "$response" | jq -r '.choices[0].message.content // empty')

    if [ -z "$response_text" ]; then
      echo "Error: Could not extract text from OpenAI response." >&2
      # echo "Full OpenAI Response: $response" >&2 # for debugging
      return 1
    fi

  elif [[ "$API_PROVIDER" == "Cerebras" ]]; then
    api_key="$CEREBRAS_API_KEY"
    api_url="https://api.cerebras.ai/v1/chat/completions"

    # Cerebras payload is like OpenRouter: { "model": "...", "messages": [...] }
    local system_message_json=$(create_api_message_json "system" "$SYSTEM_PROMPT")
    local messages_json_array_with_system=$(echo "$history_json_array" | jq --argjson sys_msg "$system_message_json" '[$sys_msg] + .')

    payload=$(jq -n --arg model "$MODEL" --argjson messages "$messages_json_array_with_system" \
      '{model: $model, messages: $messages, stream: false}')

    # Make the curl request for Cerebras
    response=$(curl -s -X POST "$api_url" \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer $api_key" \
      -d "$payload")

    # Parse Cerebras response and handle errors
    if [ $? -ne 0 ]; then
      echo "Error: curl command failed for Cerebras." >&2
      return 1
    fi

    # Check for API errors
    error_message=$(echo "$response" | jq -r '.error.message // empty')
    if [ -n "$error_message" ]; then
      echo "Error: Cerebras API Error: $error_message" >&2
      # echo "Full Cerebras Response: $response" >&2 # for debugging
      return 1
    fi

    # Extract the text content. Cerebras nests it under choices -> message -> content
    response_text=$(echo "$response" | jq -r '.choices[0].message.content // empty')

    if [ -z "$response_text" ]; then
      echo "Error: Could not extract text from Cerebras response." >&2
      # echo "Full Cerebras Response: $response" >&2 # for debugging
      return 1
    fi

  elif [[ "$API_PROVIDER" == "Ollama" ]]; then
    # Use OLLAMA_BASE_URL from .env, default if not set or empty
    local ollama_url_base="${OLLAMA_BASE_URL:-http://localhost:11434}"
    # Remove trailing slash if present
    ollama_url_base=$(echo "$ollama_url_base" | sed 's:/*$::')
    api_url="${ollama_url_base}/api/chat"

    # Ollama payload structure: { "model": "...", "messages": [...], "stream": false }
    # Messages array should include system prompt, then history.
    # create_api_message_json for "system" role:
    local system_message_json=$(create_api_message_json "system" "$SYSTEM_PROMPT")

    # history_json_array is already prepared with user/assistant messages
    # in the correct format (like OpenRouter) by the common code at the start of call_api.
    # Prepend system message to history_json_array
    local messages_json_array_with_system=$(echo "$history_json_array" | jq --argjson sys_msg "$system_message_json" '[$sys_msg] + .')

    payload=$(jq -n --arg model "$MODEL" --argjson messages "$messages_json_array_with_system" \
      '{model: $model, messages: $messages, stream: false}')

    # Make the curl request for Ollama
    # No API key typically, but Content-Type is needed.
    response=$(curl -s -X POST "$api_url" \
      -H "Content-Type: application/json" \
      -d "$payload")

    # Parse Ollama response and handle errors
    if [ $? -ne 0 ]; then
      echo "Error: curl command failed for Ollama. Is Ollama running at $ollama_url_base?" >&2
      return 1
    fi

    # Check for API errors in the response JSON (Ollama might return error in 'error' field)
    error_message=$(echo "$response" | jq -r '.error // empty')
    if [ -n "$error_message" ]; then
      echo "Error: Ollama API Error: $error_message" >&2
      # echo "Full Ollama Response: $response" >&2 # for debugging
      return 1
    fi

    # Extract the text content. Ollama nests it under message -> content
    response_text=$(echo "$response" | jq -r '.message.content // empty')

    if [ -z "$response_text" ]; then
      # Check if 'done' is false and 'message' is missing, could be an issue
      local done_status=$(echo "$response" | jq -r '.done // "true"')
      if [[ "$done_status" != "true" ]] && ! echo "$response" | jq -e '.message' > /dev/null; then
         echo "Error: Ollama response incomplete or malformed (done: $done_status, no message content)." >&2
      else
         echo "Error: Could not extract text from Ollama response. It might be empty." >&2
      fi
      # echo "Full Ollama Response: $response" >&2 # for debugging
      return 1
    fi
  else
    echo "Error: Unknown API Provider '$API_PROVIDER'." >&2
    return 1
  fi

  # 5. Return the extracted text
  echo "$response_text"
  return 0 # Indicate success
}

# --- Command Copying ---
# --- Command Copying ---
handle_command_copying() {
  local ai_response="$1"
  local line
  local -a current_copyable_items=() # Stores the full content of each block
  local -a current_preview_items=()  # Stores the preview text for gum choose
  local in_block=0
  local current_block=""

  # Use process substitution to read line by line to extract blocks
  while IFS= read -r line || [[ -n "$line" ]]; do
    # Check for closing delimiter first (only if already in a block)
    if [[ $in_block -eq 1 ]] && [[ "$line" =~ ^[[:space:]]*\`\`\`[[:space:]]*$ ]]; then
      # Exiting a block
      in_block=0
      # Store the accumulated block content if non-empty
      if [ -n "$current_block" ]; then
        # Use printf '%s' to avoid adding an extra newline at the end
        local full_block_content
        full_block_content=$(printf '%s' "$current_block")
        current_copyable_items+=("$full_block_content")

        # --- Create the preview for gum choose ---
        local first_line
        # Get first line for display, add ellipsis if multi-line
        first_line=$(echo "$full_block_content" | head -n 1)
        # Check if the block has more than one line
        if [[ $(echo "$full_block_content" | wc -l) -gt 1 ]]; then
          # Check if the first line is shorter than, say, 60 chars before adding ellipsis
          if [[ ${#first_line} -lt 60 ]]; then
            first_line="$first_line [...]"
          else
            # If the first line is long, show the first 60 chars + ellipsis
            first_line="${first_line:0:60} [...]"
          fi
        fi
        # Add the formatted first line to the preview list
        current_preview_items+=("$first_line")
        # --- End preview creation ---

      fi
      current_block="" # Reset for next potential block
    # Check for opening delimiter (only if not already in a block)
    # Allows optional language specifier (alphanumeric, _, -)
    elif [[ $in_block -eq 0 ]] && [[ "$line" =~ ^[[:space:]]*\`\`\`[a-zA-Z0-9_-]*[[:space:]]*$ ]]; then
      # Entering a block
      in_block=1
      current_block="" # Start accumulating (exclude delimiter line)
    # If inside a block, accumulate content
    elif [[ $in_block -eq 1 ]]; then
      # Append line to current block, handling the first line vs subsequent lines
      if [ -z "$current_block" ]; then
        current_block="$line"
      else
        # Append with a newline separator
        current_block=$(printf '%s\n%s' "$current_block" "$line")
      fi
    fi
  done < <(printf '%s\n' "$ai_response") # Feed the AI response line by line

  # Note: Unterminated blocks (if the AI response ends mid-block) are ignored.

  if [ ${#current_copyable_items[@]} -eq 0 ]; then
    # No code blocks found in the AI response, nothing to do.
    # You might want to add a small message or just return silently.
    # For now, returning silently is fine.
    return
  fi

  # --- Start of the new copy loop ---
  while true; do
    if [ ${#current_copyable_items[@]} -eq 0 ]; then
      echo ""
      gum style "All available blocks copied from this response." --foreground "#00FF00" --bold
      echo ""
      break # Exit the loop, all items have been copied
    fi

    local gum_options_string=""
    local -a gum_display_previews=() # To hold previews for current gum prompt

    # Prepare options for gum choose from *currently available* previews
    for i in "${!current_preview_items[@]}"; do
      # The user sees 0-indexed options for the *current* list
      gum_display_previews+=("$i: ${current_preview_items[$i]}")
    done

    local cancel_loop_option_text="Stop Copy loop"
    # Add the cancel option to the display previews array as the last item
    gum_display_previews+=("$cancel_loop_option_text")

    # Convert array to newline-separated string for gum choose
    gum_options_string=$(printf "%s\n" "${gum_display_previews[@]}")

    local selected_option
    local item_count=${#current_preview_items[@]}
    # Dynamic height for gum choose: items + cancel_option + header_space
    local gum_height=$((item_count + 2)) # +1 for cancel option, +1 for header
    # Set min/max height for gum prompt (optional, but good for usability)
    if [[ "$gum_height" -lt 3 ]]; then gum_height=3; fi
    if [[ "$gum_height" -gt 15 ]]; then gum_height=15; fi


    selected_option=$(printf "%b" "$gum_options_string" | gum choose --header "Select code block to copy (or cancel):" --height "$gum_height")
    local gum_status=$? # Capture gum exit status

    # Check if the user selected the cancel option or if gum choose was cancelled (e.g., Esc/Ctrl+C)
    if [[ "$selected_option" == "$cancel_loop_option_text" ]] || [[ -z "$selected_option" ]]; then
      echo ""
      gum style "Exiting copy mode." --foreground "#FFFF00" --bold # Yellow for exiting
      echo ""
      break # Exit the main copy loop
    else
      # Extract the index chosen by the user. This index is relative to the current list.
      local selected_index_str=$(echo "$selected_option" | cut -d':' -f1)
      local selected_index=-1

      if [[ "$selected_index_str" =~ ^[0-9]+$ ]]; then
        selected_index=$selected_index_str
      fi

      # Validate selected_index (it should be valid if gum choose worked correctly)
      if [[ $selected_index -ne -1 ]] && [[ $selected_index -lt ${#current_copyable_items[@]} ]]; then
        local content_to_copy="${current_copyable_items[$selected_index]}"
        # Get the preview text of the item being copied *before* removal for the message
        local copied_preview_text="${current_preview_items[$selected_index]}"


        printf '%s' "$content_to_copy" | $CLIPBOARD_TOOL
        echo ""
        # Use the stored preview for the message
        gum style "Copied block: '${copied_preview_text}' to clipboard!" --foreground "#00FF00" --bold
        echo ""

        # --- Remove the copied item from BOTH arrays ---
        local temp_copyable=()
        for i in "${!current_copyable_items[@]}"; do
          if [[ $i -ne $selected_index ]]; then
            temp_copyable+=("${current_copyable_items[$i]}")
          fi
        done
        current_copyable_items=("${temp_copyable[@]}")
        unset temp_copyable

        local temp_previews=()
        for i in "${!current_preview_items[@]}"; do
          if [[ $i -ne $selected_index ]]; then
            temp_previews+=("${current_preview_items[$i]}")
          fi
        done
        current_preview_items=("${temp_previews[@]}")
        unset temp_previews
        # --- End of removal ---
      else
        echo "Error: Invalid selection. Returning to copy options." >&2
        # Loop will continue, offering the (now potentially smaller) list again.
      fi
    fi
  done
  # --- End of the new copy loop ---
}

# --- Main Chat Loop ---
main() {
  # Display ASCII Art Welcome
  echo -e "\e[1;35m" # Set color to bold purple
  echo "  ,-.   ,-."
  echo " ( O ) (o.o)"
  echo "  \`-’   |_)  oliveowl"
  echo "    “who?”"
  echo -e "\e[0m" # Reset color and bold

  # Check if configuration is complete before starting chat
  if [ -z "$API_PROVIDER" ] || [ -z "$MODEL" ]; then
    echo "Configuration incomplete." >&2
    echo "Please run '$0 --config' first to select API provider and model." >&2
    exit 1
  fi

  # Display Welcome and Instructions using echo with ANSI colors
  echo -e "\e[0;94mWelcome to \e[1;35mOliveOwl\e[0;94m! Provider: \e[1;35m$API_PROVIDER\e[0;94m, Model: \e[1;35m$MODEL\e[0m"
  echo -e "\e[0;94mType \e[1;35m/exit\e[0;94m to quit, \e[1;35m/history\e[0;94m to load previous chat, \e[1;35m/new\e[0;94m for new chat, \e[1;35m/config\e[0;94m to reconfigure.\e[0m"
  echo -e "\e[0;94mType \e[1;35m/view\e[0;94m to open current history in \e[1;35m$EDITOR\e[0m.\e[0m" # Add /view instruction

  # Initial session setup
  local start_status
  start_new_session # Prompt user for initial action (new, history, exit)
  start_status=$?
  if [ $start_status -ne 0 ]; then
    # If /history was chosen but failed or was cancelled, start a default new session
    echo "Falling back to new timestamped session."
    create_new_session_file "" # Create default timestamped session
  fi
  # If start_new_session exited or loaded history successfully, we proceed

  # Main loop
  while true; do
    # --- Read user input using gum write ---
    local user_input=""
    # Display prompt manually before calling gum
    printf '\n\e[1;34mYou:\e[0m\n' # Print "You:" prompt on its own line (Bold Blue)

    # Use gum write to capture multi-line input.
    # Set a placeholder to encourage input.
    # Capture output into user_input variable.
    # Check exit status to handle cancellation (e.g., Ctrl+C in gum write).
    if ! user_input=$(gum write --placeholder "Enter your prompt (Ctrl+D or Esc to finish)..."); then
      # gum write was cancelled (e.g., Ctrl+C)
      echo "Input cancelled."
      # Decide how to handle cancellation - exit or continue loop? Let's continue.
      continue
    fi
    # --- End of gum write input ---

    # Trim leading/trailing whitespace (optional, but often helpful)
    # Also remove placeholder if user exits without typing (gum write might return the placeholder)
    local placeholder="Enter your prompt (Ctrl+D or Esc to finish)..."
    if [[ "$user_input" == "$placeholder" ]]; then
      user_input=""
    fi
    user_input=$(echo "$user_input" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')

    # Handle commands (check the input captured from gum)
    # Commands must be the entire input now, not just the first line.
    local is_command_handled=0 # Flag to check if a command was processed
    case "$user_input" in
    "/exit")
      is_command_handled=1
      echo "Exiting OliveOwl."
      break
      ;;
    "/new")
      is_command_handled=1
      # Prompt again for new session name, history load, or exit
      local new_status
      start_new_session
      new_status=$?
      if [ $new_status -ne 0 ]; then
        # If /history was chosen but failed or was cancelled, start a default new session
        echo "Falling back to new timestamped session."
        create_new_session_file "" # Create default timestamped session
      fi
      continue # Skip API call for this turn
      ;;
    "/history")
      is_command_handled=1
      # Just attempt to load history, don't change session if cancelled
      select_and_load_history
      continue # Skip API call for this turn
      ;;
    "/config")
      is_command_handled=1
      echo "Switching to config..."
      configure_settings # Re-run config
      # Re-source config in case it changed
      # Re-source config in case it changed
      # Check if CONFIG_FILE exists before sourcing
      if [ -f "$CONFIG_FILE" ]; then
        source "$CONFIG_FILE"
      fi
      echo "Config updated. Provider: $API_PROVIDER, Model: $MODEL"
      # After config, continue the current session with the new settings
      continue
      ;;
    "/view")
      is_command_handled=1
      view_history # Call the new function
      continue     # Skip API call for this turn
      ;;

    "")                    # Handle empty input
      is_command_handled=1 # Treat empty input like a command (skip API call)
      continue
      ;;
    esac

    # If input was not a command and not empty, print it back before API call
    if [[ $is_command_handled -eq 0 ]] && [ -n "$user_input" ]; then
      # The "You:" prompt was already printed before gum write.
      # Just print the captured input. Use printf to handle potential special chars.
      printf '%s\n' "$user_input"
    fi

    # Add user message to history (as a wrapper object string)
    # Only add non-empty, non-command input to history
    if [[ $is_command_handled -eq 0 ]] && [ -n "$user_input" ]; then
      local user_api_json=$(create_api_message_json "user" "$user_input")
      local user_history_item=$(jq -n --argjson msg "$user_api_json" --arg model "" \
        '{message_json: $msg, model_used: $model}' | jq -c .)
      CHAT_HISTORY+=("$user_history_item")
      # Save history immediately after adding user message
      if ! save_history; then
        echo "Warning: Failed to save history after user input." >&2
      fi
    # Skip API call if it was a command or empty input
    else
      continue
    fi

    # Call the API with gum spinner and retry logic
    local ai_response=""      # Initialize ai_response
    local api_call_status=1   # Initialize to failure status (1 means error)
                              # This variable will store the *final* status of the API call attempt(s).

    # --- Start of API call retry loop ---
    while true; do
        local current_attempt_status # Status for the current try inside the loop
        local spinner_pid
        local start_time end_time # Declare variables for timing

        # Start spinner in the background for this attempt
        gum spin --spinner dot --title "Waiting for AI response..." -- sleep infinity &
        spinner_pid=$!
        trap 'kill $spinner_pid 2>/dev/null; trap - EXIT' EXIT

        start_time=$(date +%s%N) # Capture start time in nanoseconds

        # Call the API synchronously in the foreground
        ai_response=$(call_api "$user_input")
        current_attempt_status=$?

        end_time=$(date +%s%N) # Capture end time in nanoseconds

        # Stop the spinner for this attempt
        kill $spinner_pid 2>/dev/null
        trap - EXIT

        if [ $current_attempt_status -eq 0 ] && [ -n "$ai_response" ]; then
            # API call successful for this attempt
            api_call_status=0 # Set final status to success
            break # Exit the retry loop
        else
            # API call failed for this attempt
            # The error message from call_api (e.g., "Error: Gemini API Error: ...")
            # should have already been printed by the call_api function itself.
            # We will add a general failure message before the gum choose prompt.

            echo "Error: API call failed." # General notification for this attempt

            local choice
            # Use gum choose to ask the user if they want to retry or cancel.
            # The header should clearly state the problem.
            choice=$(gum choose "Retry" "Cancel" --header "API call failed. What would you like to do?")
            local gum_choose_status=$? # Get exit status of gum choose

            if [[ $gum_choose_status -ne 0 ]] || [[ "$choice" == "Cancel" ]]; then
                # User chose Cancel or gum choose was cancelled (e.g., ESC or Ctrl+C)
                echo "API call attempt cancelled by user."
                ai_response=""    # Ensure ai_response is empty to signify overall failure/cancellation
                api_call_status=1 # Keep final status as failure
                exit 0
            elif [[ "$choice" == "Retry" ]]; then
                # User chose Retry
                echo "Retrying API call for prompt: \"$user_input\""
                # The 'while true' loop will continue, and call_api will be attempted again.
                # No need to do anything else here, just let the loop iterate.
                continue
            fi
        fi
    done
    # --- End of API call retry loop ---

    # Check the final api_call_status after the retry loop has finished
    if [ $api_call_status -ne 0 ] || [ -z "$ai_response" ]; then
      # This block is entered if:
      # 1. The initial API call failed AND the user chose "Cancel" in the retry prompt.
      # 2. (Less likely) call_api returned status 0 but an empty response, and this somehow wasn't caught earlier.

      # The "Error: API call failed." or "API call attempt cancelled by user." message
      # would have been printed inside the loop.
      # Now, handle the consequence: remove the user's prompt from history.
      # This is because the user's input was added to CHAT_HISTORY *before* this API call block.
      if [ ${#CHAT_HISTORY[@]} -gt 0 ]; then
        unset 'CHAT_HISTORY[-1]' # Remove the last user message that failed
        # Attempt to save history to reflect the removal
        if ! save_history; then
          echo "Warning: Failed to save history after cancelling/failing API call for the prompt." >&2
        fi
      fi
      # Continue to the next iteration of the main chat loop to get new user input.
      continue
    fi

    # --- Calculate and Display Token Speed ---
    # This block runs only if the API call was ultimately successful (api_call_status == 0)
    # and ai_response is populated. The start_time and end_time were set
    # during the *last successful attempt* within the retry loop.

    local time_taken_ns=$((end_time - start_time))
    # Convert nanoseconds to seconds (float) for calculation. Use bc for precision.
    # Ensure scale is sufficient for small time differences.
    local time_taken_s=$(echo "scale=3; $time_taken_ns / 1000000000" | bc)

    # Count words in the AI response
    # `wc -w` counts words. Use process substitution to feed the response.
    local word_count=$(echo -n "$ai_response" | wc -w)

    local words_per_second="N/A" # Default if time_taken_s is zero or word_count is zero

    # Avoid division by zero if time_taken_s is 0 or very close to 0, or if word_count is 0
    # bc returns 0 if the result of division is less than its scale allows without truncation.
    # We should check if time_taken_s is greater than a very small threshold like 0.001.
    # A simpler check is if word_count > 0 and time_taken_s is not "0.000" (or similar for your scale)
    if [ "$word_count" -gt 0 ] && [ "$(echo "$time_taken_s > 0.000" | bc -l)" -eq 1 ]; then
        words_per_second=$(echo "scale=2; $word_count / $time_taken_s" | bc)
    elif [ "$word_count" -gt 0 ] && [ "$time_taken_s" == "0.000" ]; then # Handle case where time is too short for bc with current scale
        words_per_second="Effectively Instant (words: $word_count)"
    fi
    # --- End of Token Speed Calculation ---


    # Add AI response to history
    # Use the correct role based on the API provider for the response
    local response_role="assistant" # Default for OpenRouter
    if [[ "$API_PROVIDER" == "Gemini" ]]; then
      response_role="model"
    fi
    # Add AI response to history (as a wrapper object string)
    local ai_api_json=$(create_api_message_json "$response_role" "$ai_response")
    local ai_history_item=$(jq -n --argjson msg "$ai_api_json" --arg model "$MODEL" \
      '{message_json: $msg, model_used: $model}' | jq -c .)
    CHAT_HISTORY+=("$ai_history_item")

    # Save history after successful call
    # Save history *after* adding the AI response
    if ! save_history; then
      # Handle save error if needed, maybe just continue
      echo "Warning: Failed to save history after AI response." >&2
    fi

    # Interpret the raw AI response first
    local interpreted_response
    interpreted_response=$(printf '%b' "$ai_response")

    # Display interpreted AI response using bat
    echo -e "\n\e[1;35mAI ($MODEL):\e[0m"                                        # Bold Purple for AI
    echo -e "\e[1m\e[35m=============================================\e[0m" # Bold Purple for AI, showing specific model, with explicit reset
    echo "$interpreted_response" | bat --language md --paging=never --style=plain --color=always
    # Display token speed (words per second)
    # Use a different color for the speed, perhaps a subtle grey or cyan.
    # \e[0;90m is dark grey. \e[0;36m is cyan.
    echo -e "\e[0;90mSpeed: $words_per_second words/sec (Time: ${time_taken_s}s, Words: $word_count)\e[0m"

    # Handle command copying using the interpreted response
    handle_command_copying "$interpreted_response"

  done
}

# --- Argument Parsing ---
if [[ "$1" == "--config" ]]; then
  setup_config # Ensure .env is loaded first for API key checks
  configure_settings
  exit 0
fi

# --- Run Setup and Main ---
# Setup needs to run first to load config for main
setup_config
# Check EDITOR dependency after setup_config sets/loads it
check_dependency "$EDITOR"
main

exit 0
